#
# hadoop.log
#
hadoop.log.dir=.
hadoop.log.file=hadoop.log

#
# hadoop.root
#
hadoop.root.logger=INFO,console

#
# hadoop.tasklog
#
hadoop.tasklog.logsRetainHours=12
hadoop.tasklog.noKeepSplits=4
hadoop.tasklog.purgeLogSplits=true
hadoop.tasklog.taskid=null
hadoop.tasklog.totalLogFileSize=100

#
# log4j.appender.console
#
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n
log4j.appender.console.target=System.err

#
# log4j.appender.DRFA
#
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.DatePattern=.yyyy-MM-dd
log4j.appender.DRFA.File=${hadoop.log.dir}/${hadoop.log.file}
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n

#
# log4j.appender.EventCounter
#
log4j.appender.EventCounter=org.apache.hadoop.metrics.jvm.EventCounter

#
# log4j.appender.RFA
#
log4j.appender.RFA=org.apache.log4j.RollingFileAppender
log4j.appender.RFA.File=${hadoop.log.dir}/${hadoop.log.file}
log4j.appender.RFA.layout=org.apache.log4j.PatternLayout
log4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.RFA.MaxBackupIndex=30
log4j.appender.RFA.MaxFileSize=200MB

#
# log4j.appender.TLA
#
log4j.appender.TLA=org.apache.hadoop.mapred.TaskLogAppender
log4j.appender.TLA.layout=org.apache.log4j.PatternLayout
log4j.appender.TLA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.TLA.taskId=${hadoop.tasklog.taskid}
log4j.appender.TLA.totalLogFileSize=${hadoop.tasklog.totalLogFileSize}

#
# log4j.logger
#
log4j.logger.org.apache.hadoop.fs.FSNamesystem.audit=WARN
log4j.logger.org.jets3t.service.impl.rest.httpclient.RestS3Service=ERROR

#
# log4j.rootLogger
#
log4j.rootLogger=${hadoop.root.logger}, EventCounter

#
# log4j.threshhold
#
log4j.threshhold=ALL
