#
# hadoop.log
#
hadoop.log.dir=.
hadoop.log.file=hadoop.log

#
# hadoop.root
#
hadoop.root.logger=INFO,console

#
# hadoop.tasklog
#
hadoop.tasklog.logsRetainHours=12
hadoop.tasklog.noKeepSplits=4
hadoop.tasklog.purgeLogSplits=true
hadoop.tasklog.taskid=null
hadoop.tasklog.totalLogFileSize=100

#
# log4j.additivity
#
log4j.additivity.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=false
log4j.additivity.org.apache.hadoop.hdfs.StateChange=false
log4j.additivity.org.apache.hadoop.ipc=false
log4j.additivity.org.apache.hadoop.mapred.JobHistory.stream=false

#
# log4j.appender.audit
#
log4j.appender.audit=org.apache.log4j.RollingFileAppender
log4j.appender.audit.File=${hadoop.log.dir}/audit.log
log4j.appender.audit.layout=org.apache.log4j.PatternLayout
log4j.appender.audit.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.audit.MaxBackupIndex=120
log4j.appender.audit.MaxFileSize=500MB

#
# log4j.appender.console
#
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n
log4j.appender.console.target=System.err

#
# log4j.appender.DRFA
#
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.DatePattern=.yyyy-MM-dd
log4j.appender.DRFA.File=${hadoop.log.dir}/${hadoop.log.file}
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n

#
# log4j.appender.EventCounter
#
log4j.appender.EventCounter=org.apache.hadoop.metrics.jvm.EventCounter

#
# log4j.appender.jobhistory
#
log4j.appender.jobhistory=org.apache.hadoop.util.YTAppender
log4j.appender.jobhistory.BufferedIO=true
log4j.appender.jobhistory.BufferSize=8192
log4j.appender.jobhistory.DatePattern=.yyyy-MM-dd-HH
log4j.appender.jobhistory.File=${hadoop.log.dir}/newHistory/jobhistory.log
log4j.appender.jobhistory.layout=org.apache.log4j.PatternLayout

#
# log4j.appender.nnstate
#
log4j.appender.nnstate=org.apache.log4j.RollingFileAppender
log4j.appender.nnstate.BufferedIO=true
log4j.appender.nnstate.BufferSize=16384
log4j.appender.nnstate.File=${hadoop.log.dir}/stateChange.log
log4j.appender.nnstate.layout=org.apache.log4j.PatternLayout
log4j.appender.nnstate.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.nnstate.MaxBackupIndex=30
log4j.appender.nnstate.MaxFileSize=500MB

#
# log4j.appender.RFA
#
log4j.appender.RFA=org.apache.log4j.RollingFileAppender
log4j.appender.RFA.File=${hadoop.log.dir}/${hadoop.log.file}
log4j.appender.RFA.layout=org.apache.log4j.PatternLayout
log4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.RFA.MaxBackupIndex=30
log4j.appender.RFA.MaxFileSize=200MB

#
# log4j.appender.rpc
#
log4j.appender.rpc=org.apache.log4j.RollingFileAppender
log4j.appender.rpc.BufferedIO=true
log4j.appender.rpc.BufferSize=8192
log4j.appender.rpc.File=${hadoop.log.dir}/RPC.log
log4j.appender.rpc.layout=org.apache.log4j.PatternLayout
log4j.appender.rpc.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.rpc.MaxBackupIndex=30
log4j.appender.rpc.MaxFileSize=500MB

#
# log4j.appender.TLA
#
log4j.appender.TLA=org.apache.hadoop.mapred.TaskLogAppender
log4j.appender.TLA.layout=org.apache.log4j.PatternLayout
log4j.appender.TLA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
log4j.appender.TLA.taskId=${hadoop.tasklog.taskid}
log4j.appender.TLA.totalLogFileSize=${hadoop.tasklog.totalLogFileSize}

#
# log4j.logger
#
log4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=INFO,audit
log4j.logger.org.apache.hadoop.hdfs.StateChange=INFO,nnstate
log4j.logger.org.apache.hadoop.ipc=INFO,rpc
log4j.logger.org.apache.hadoop.mapred.JobHistory.stream=INFO,jobhistory
log4j.logger.org.jets3t.service.impl.rest.httpclient.RestS3Service=ERROR

#
# log4j.rootLogger
#
log4j.rootLogger=${hadoop.root.logger}, EventCounter

#
# log4j.threshhold
#
log4j.threshhold=ALL
